{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doc2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEbFVQGrLroWhoymxDDF/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Woracle/Doc2Vec_pytorch/blob/main/Doc2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXAEiNUWXwF0"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py\n",
        "\n",
        "Developed as a tweak to the example on above link. Rather than make word2vec i created a doc2vec method based on training an embedding for each document label. Next step would be to wrap the module and method etc \n",
        "within a formal class and store information such as which words in the vocab are documents and which are words, for easier information retrieval. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPPYHXF3QDA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AIbOeBy3RSl"
      },
      "source": [
        "lstm = nn.LSTM(3,3)\n",
        "\n",
        "inputs = [torch.randn(1, 3) for _ in range(5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P54cwBkl3e84"
      },
      "source": [
        "hidden = (torch.randn(1,1,3), torch.randn(1,1,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVpL9DHp8YKf",
        "outputId": "a028b7b2-74fa-41e2-cec0-35404746ea0c"
      },
      "source": [
        "hidden[0].view(1, 1, -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0708, -0.4503, -0.1727]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytPzwPQ3sU0",
        "outputId": "0b37dad9-5cfe-4c16-db90-e75106c5976b"
      },
      "source": [
        "for i in inputs:\n",
        "  print(i.view(1, 1, -1))\n",
        "  out , hidden = lstm(i.view(1, 1, -1), hidden)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.9961,  1.0446, -0.7019]]])\n",
            "tensor([[[-0.4111, -0.2937,  0.4871]]])\n",
            "tensor([[[-0.6553,  1.2947, -2.0795]]])\n",
            "tensor([[[ 1.1747, -1.1901, -0.8126]]])\n",
            "tensor([[[-1.1561, -0.5007,  0.0127]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnyLelIg4Qc6",
        "outputId": "8658c69e-bd74-4f79-a2d8-e0c7ae092c37"
      },
      "source": [
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.9961,  1.0446, -0.7019]]),\n",
              " tensor([[-0.4111, -0.2937,  0.4871]]),\n",
              " tensor([[-0.6553,  1.2947, -2.0795]]),\n",
              " tensor([[ 1.1747, -1.1901, -0.8126]]),\n",
              " tensor([[-1.1561, -0.5007,  0.0127]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1LGY-1I35Cb",
        "outputId": "035f8a1d-8f83-43bb-e176-10bdc2bb485d"
      },
      "source": [
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4259, 0.0674, 0.2460]]], grad_fn=<StackBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEekRv6k4LQ_",
        "outputId": "93c20dcc-f3e4-45b8-d0d6-a58253abed13"
      },
      "source": [
        "hidden"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.4259, 0.0674, 0.2460]]], grad_fn=<StackBackward>),\n",
              " tensor([[[0.5782, 0.1903, 0.9118]]], grad_fn=<StackBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th7MuVXE3_Bl"
      },
      "source": [
        "# lets explore word embeddings\n",
        "\n",
        "word_to_ix = {\"This\": 0, \"is\": 1, \"an\": 2, \"experiment\": 3}\n",
        "\n",
        "embeds = nn.Embedding(len(word_to_ix), 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0vkJ2qZ-Vd9"
      },
      "source": [
        "exp = torch.tensor([word_to_ix[\"experiment\"]],dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIP5WtwB-j4k",
        "outputId": "4bdcf36f-3b2c-4576-e414-731fef8a5f42"
      },
      "source": [
        "embeds(exp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6283,  0.5514,  0.2731,  0.6019, -1.0703]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7UUzPFuGIIN"
      },
      "source": [
        "# can i build a doc 2 vec here\n",
        "\n",
        "Context_size = 2\n",
        "text = {\"doc1\" : \"This is our first document  for exploring\".split(),\n",
        "        \"doc2\" : \"The red cat sat in a hat and ate cheese\".split(),\n",
        "        \"doc3\" : \"Another couple of sentences later and we have doc2vec\".split()}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX31KHSlf-_s"
      },
      "source": [
        "vocab = []\n",
        "\n",
        "for doc in text:\n",
        "  vocab = vocab + text[doc]\n",
        "\n",
        "vocab = list(text.keys()) + vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME1fkpVAkAPn",
        "outputId": "f08d7750-47cb-4f2f-cd49-93904aef98df"
      },
      "source": [
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['doc1',\n",
              " 'doc2',\n",
              " 'doc3',\n",
              " 'This',\n",
              " 'is',\n",
              " 'our',\n",
              " 'first',\n",
              " 'document',\n",
              " 'for',\n",
              " 'exploring',\n",
              " 'The',\n",
              " 'red',\n",
              " 'cat',\n",
              " 'sat',\n",
              " 'in',\n",
              " 'a',\n",
              " 'hat',\n",
              " 'and',\n",
              " 'ate',\n",
              " 'cheese',\n",
              " 'Another',\n",
              " 'couple',\n",
              " 'of',\n",
              " 'sentences',\n",
              " 'later',\n",
              " 'and',\n",
              " 'we',\n",
              " 'have',\n",
              " 'doc2vec']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svUvj9cGhhp6",
        "outputId": "0304cc07-b669-4487-a72b-4ccf6f7f3a9b"
      },
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "data = []\n",
        "for j in text:\n",
        "  for i in range(2, len(text[j]) - 2):\n",
        "      context = [j, text[j][i - 2], text[j][i - 1],\n",
        "                text[j][i + 1], text[j][i + 2]]\n",
        "      target = text[j][i]\n",
        "      data.append((context, target))\n",
        "print(data[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(['doc1', 'This', 'is', 'first', 'document'], 'our'), (['doc1', 'is', 'our', 'document', 'for'], 'first'), (['doc1', 'our', 'first', 'for', 'exploring'], 'document'), (['doc2', 'The', 'red', 'sat', 'in'], 'cat'), (['doc2', 'red', 'cat', 'in', 'a'], 'sat')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v50PDhpuJTmQ"
      },
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def make_target_vector(target, word_to_ix):\n",
        "  idx = word_to_ix[target]\n",
        "  return torch.tensor(idx, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0ZYjzNQPO5_",
        "outputId": "bdb0d0fc-574d-4af9-c18e-f3db96376b1c"
      },
      "source": [
        "word_to_ix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Another': 20,\n",
              " 'The': 10,\n",
              " 'This': 3,\n",
              " 'a': 15,\n",
              " 'and': 25,\n",
              " 'ate': 18,\n",
              " 'cat': 12,\n",
              " 'cheese': 19,\n",
              " 'couple': 21,\n",
              " 'doc1': 0,\n",
              " 'doc2': 1,\n",
              " 'doc2vec': 28,\n",
              " 'doc3': 2,\n",
              " 'document': 7,\n",
              " 'exploring': 9,\n",
              " 'first': 6,\n",
              " 'for': 8,\n",
              " 'hat': 16,\n",
              " 'have': 27,\n",
              " 'in': 14,\n",
              " 'is': 4,\n",
              " 'later': 24,\n",
              " 'of': 22,\n",
              " 'our': 5,\n",
              " 'red': 11,\n",
              " 'sat': 13,\n",
              " 'sentences': 23,\n",
              " 'we': 26}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfBeIYerwyOP"
      },
      "source": [
        "rec = np.empty(shape=(14,5))\n",
        "\n",
        "for i,  row in enumerate(data):\n",
        "  rec[i] = make_context_vector(data[i][0], word_to_ix= word_to_ix)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZDd2ogHIgrs",
        "outputId": "3a445b3d-4d01-4229-9e15-6b84728344b3"
      },
      "source": [
        "word_to_ix[data[1][1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpwJMQLYt5JA"
      },
      "source": [
        "rec = torch.from_numpy(rec)\n",
        "targ = torch.from_numpy(targ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLJemWPj7FR9",
        "outputId": "7760d549-2284-449b-c678-e3271794b887"
      },
      "source": [
        "rec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  3.,  4.,  6.,  7.],\n",
              "        [ 0.,  4.,  5.,  7.,  8.],\n",
              "        [ 0.,  5.,  6.,  8.,  9.],\n",
              "        [ 1., 10., 11., 13., 14.],\n",
              "        [ 1., 11., 12., 14., 15.],\n",
              "        [ 1., 12., 13., 15., 16.],\n",
              "        [ 1., 13., 14., 16., 25.],\n",
              "        [ 1., 14., 15., 25., 18.],\n",
              "        [ 1., 15., 16., 18., 19.],\n",
              "        [ 2., 20., 21., 23., 24.],\n",
              "        [ 2., 21., 22., 24., 25.],\n",
              "        [ 2., 22., 23., 25., 26.],\n",
              "        [ 2., 23., 24., 26., 27.],\n",
              "        [ 2., 24., 25., 27., 28.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv6Ye0pmyoHk"
      },
      "source": [
        "class Doc2Vec(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "    super(Doc2Vec, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim) # the output of the embedding layer is a tensor for each word so 5 tensors of emedding dim long\n",
        "    self.linear = nn.Linear(context_size * embedding_dim, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    embeds = self.embeddings(inputs)\n",
        "    out = self.linear(embeds.view(1,-1))\n",
        "    log_probs = F.log_softmax(out, dim=1)\n",
        "    return log_probs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8ERQO8h0WPH"
      },
      "source": [
        "embeddings = nn.Embedding(len(vocab), 10)\n",
        "linear = nn.Linear(50, len(vocab))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpYgYFsH0nnb"
      },
      "source": [
        "embs = embeddings(rec[13, :].type(torch.long))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMfmd6bRBt3q",
        "outputId": "a462ac76-5c9f-4545-fc6b-cf7766787705"
      },
      "source": [
        "embs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1124, -0.4338,  0.1170, -0.1787,  1.0799,  0.2531, -1.2409, -0.6822,\n",
              "         -0.3185,  1.1176],\n",
              "        [-0.5583, -0.2488,  0.8714, -0.1752,  0.1384, -1.1334, -0.9564,  0.3587,\n",
              "          1.6018,  1.1322],\n",
              "        [-0.3461,  1.6263, -0.0739,  0.2127,  0.6517,  0.1587,  0.6815, -0.0901,\n",
              "          0.2385,  0.5890],\n",
              "        [ 0.0043, -0.8064,  0.0291,  0.1963,  0.7239,  0.0136,  0.0103,  0.3219,\n",
              "         -1.2149,  0.7407],\n",
              "        [ 0.5951,  1.8907, -0.2101, -1.6978, -0.0039, -1.6067, -1.6329,  0.5005,\n",
              "          1.5389,  1.2314]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfLuNkNJAsSz"
      },
      "source": [
        "model = Doc2Vec(vocab_size=len(vocab), embedding_dim= 10, context_size= 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRhC5zJF8omV"
      },
      "source": [
        "log_probs = model(rec[1, :].type(torch.long))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIqHJQlcHjYu",
        "outputId": "8279729b-d63f-486d-e4da-a03cb9b8efef"
      },
      "source": [
        "log_probs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.5496, -3.3986, -3.9204, -2.5497, -4.3944, -3.4811, -3.0037, -2.0418,\n",
              "         -3.3976, -2.9969, -3.6387, -4.4810, -4.2514, -3.7076, -3.8133, -2.8552,\n",
              "         -3.2783, -3.4504, -3.2052, -4.3678, -4.0273, -4.1972, -3.4334, -3.5503,\n",
              "         -4.1352, -3.8756, -4.1995, -3.7846, -3.2796]],\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0SX90ifHy3t"
      },
      "source": [
        "loss_function = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0IzPrwLL9rq",
        "outputId": "63e27501-e2d7-451c-eda7-78f06e395bee"
      },
      "source": [
        "targ[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFSsLErQIHui"
      },
      "source": [
        "loss = loss_function(log_probs, targ[1].type(torch.long))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gGxMlf7N9fe",
        "outputId": "487b186b-a6e3-448a-9745-f83935e71de4"
      },
      "source": [
        "rec[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 4., 5., 7., 8.], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iixLuOnVOK4I",
        "outputId": "b037a9a5-c3bb-4c47-9d2a-0c2042632447"
      },
      "source": [
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = Doc2Vec(vocab_size=len(vocab), embedding_dim= 10, context_size= 5)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
        "\n",
        "for epoch in range(100):\n",
        "  total_loss = 0\n",
        "  for i in range(len(rec)):\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    log_probs = model(rec[i].type(torch.long))\n",
        "\n",
        "    loss = loss_function(log_probs, targ[i].type(torch.long))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "  \n",
        "  losses.append(total_loss)\n",
        "print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[47.39168453216553, 45.407543659210205, 43.45357966423035, 41.53386163711548, 39.652857542037964, 37.81536543369293, 36.02639925479889, 34.29104030132294, 32.61424505710602, 31.000614047050476, 29.454163312911987, 27.978100419044495, 26.574644565582275, 25.24492347240448, 23.988940238952637, 22.805635392665863, 21.69302123785019, 20.648351967334747, 19.6683269739151, 18.749293744564056, 17.88741832971573, 17.078831046819687, 16.31974032521248, 15.606509894132614, 14.93570727109909, 14.304137468338013, 13.708848595619202, 13.14713191986084, 12.61651685833931, 12.114751622080803, 11.639790132641792, 11.189775809645653, 10.763016238808632, 10.357974261045456, 9.973248846828938, 9.607558496296406, 9.259732238948345, 8.92869370430708, 8.613452769815922, 8.313098810613155, 8.02678445726633, 7.753725975751877, 7.493195429444313, 7.24451270699501, 7.0070458091795444, 6.780197869986296, 6.563415169715881, 6.35617370903492, 6.157983168959618, 5.9683836586773396, 5.786938086152077, 5.6132372841238976, 5.4468940533697605, 5.287541478872299, 5.134835463017225, 4.98844987899065, 4.8480749651789665, 4.713418802246451, 4.584205027669668, 4.460171470418572, 4.341072883456945, 4.226670617237687, 4.116744676604867, 4.011084105819464, 3.909487545490265, 3.8117668461054564, 3.717742796987295, 3.627244083210826, 3.5401101149618626, 3.4561856240034103, 3.3753273617476225, 3.2973942775279284, 3.2222584392875433, 3.1497945226728916, 3.079884571954608, 3.0124149210751057, 2.947279185988009, 2.88437663577497, 2.8236101027578115, 2.7648884411901236, 2.7081249821931124, 2.6532363016158342, 2.600143407471478, 2.5487713692709804, 2.499048799276352, 2.450908216647804, 2.40428299177438, 2.3591142501682043, 2.3153417175635695, 2.2729103481397033, 2.231764947064221, 2.1918568583205342, 2.153136861510575, 2.1155573120340705, 2.0790764205157757, 2.043650306761265, 2.009240127168596, 1.975805526599288, 1.9433113159611821, 1.9117219764739275]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Loq6Mb1GWP0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e1237a-4687-4368-aa1a-3cd589aab7e3"
      },
      "source": [
        "doc4 = \"This is exploring our first document\".split()\n",
        "\n",
        "doc4embs = [model.embeddings.weight[word_to_ix[word]] for word in doc4]\n",
        "\n",
        "doc4embs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([-0.2182,  0.4983,  0.1173,  0.0914,  0.3153, -0.5963, -1.0619,  0.8877,\n",
              "          0.3174, -0.9643], grad_fn=<SelectBackward>),\n",
              " tensor([-2.6197, -3.0649, -0.0554,  0.6509,  0.7018, -0.1657,  0.2540,  1.7208,\n",
              "          0.3995,  0.4790], grad_fn=<SelectBackward>),\n",
              " tensor([-0.3405, -0.9031, -1.3256, -0.2440,  0.3910,  0.5161,  0.5112, -0.7389,\n",
              "         -0.7672,  1.3889], grad_fn=<SelectBackward>),\n",
              " tensor([ 1.8204,  0.0410, -0.1428, -0.9709, -0.7335,  1.2012,  0.1200, -0.4249,\n",
              "          1.4659,  1.4000], grad_fn=<SelectBackward>),\n",
              " tensor([-1.9927, -2.4304,  0.0723,  0.3660,  0.5282,  0.4519,  1.2636,  0.4118,\n",
              "         -1.9838,  1.6796], grad_fn=<SelectBackward>),\n",
              " tensor([-1.5148, -1.1591,  0.2386,  1.5738, -0.9429,  1.5610, -0.1037,  0.1501,\n",
              "          1.5666,  0.4109], grad_fn=<SelectBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcEUzxxvWRiw"
      },
      "source": [
        "doc4vector = torch.mean(torch.stack(doc4embs), dim = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMOamuNvQpdw"
      },
      "source": [
        "doc1vector = model.embeddings.weight[word_to_ix[\"doc1\"]]\n",
        "doc2vector = model.embeddings.weight[word_to_ix[\"doc2\"]]\n",
        "doc3vector = model.embeddings.weight[word_to_ix[\"doc3\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM7D2dEFXZM2"
      },
      "source": [
        "d4 = doc4vector.detach().numpy()\n",
        "d1 = doc1vector.detach().numpy()\n",
        "d2 = doc2vector.detach().numpy()\n",
        "d3 = doc3vector.detach().numpy()\n",
        "\n",
        "cos_sim41 =  ( d4 @ d1.T) / (np.linalg.norm(d4)*np.linalg.norm(d1))\n",
        "cos_sim42 =  ( d4 @ d2.T) / (np.linalg.norm(d4)*np.linalg.norm(d2))\n",
        "cos_sim43 =  ( d4 @ d3.T) / (np.linalg.norm(d4)*np.linalg.norm(d3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuKaS5bgYXHW",
        "outputId": "1f3313f1-1364-42ea-ad41-f5ce1fec35da"
      },
      "source": [
        "cos_sim41, cos_sim42, cos_sim43"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.07801964, -0.02057004, 0.7141524)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjFXGmKTc88R"
      },
      "source": [
        "The Averaging technique used above to generate doc4's vectors has returned quite an odd result. where doc2 and doc 4 are the most similiar 1 and 4 are close "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WitVlBSZfCu",
        "outputId": "3a7eec1c-dc90-4f77-954a-aa4c82807cbf"
      },
      "source": [
        "print(text[\"doc1\"])\n",
        "print(doc4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'our', 'first', 'document', 'for', 'exploring']\n",
            "['This', 'is', 'exploring', 'our', 'first', 'document']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}